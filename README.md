# wayback_robots

It finds all paths from robots.txt from all-time snapshotted on  http://web.archive.org   and parses it and converts into urls

# usage

For one domain

```
 ./wayback_robots.sh -d example.com
```

For  domains from input file 

```
 ./wayback_robots.sh -f file.txt
```

# credits
Inspired from [mhmdiaa](https://gist.github.com/mhmdiaa/)

